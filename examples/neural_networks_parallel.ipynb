{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching (::Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}})()\n\n\u001b[0mClosest candidates are:\n\u001b[0m  (::Chain)(\u001b[91m::Any\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mFlux\u001b[39m \u001b[90m~/.julia/packages/Flux/Wz6D4/src/layers/\u001b[39m\u001b[90m\u001b[4mbasic.jl:51\u001b[24m\u001b[39m\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching (::Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}})()\n\n\u001b[0mClosest candidates are:\n\u001b[0m  (::Chain)(\u001b[91m::Any\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mFlux\u001b[39m \u001b[90m~/.julia/packages/Flux/Wz6D4/src/layers/\u001b[39m\u001b[90m\u001b[4mbasic.jl:51\u001b[24m\u001b[39m\n",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[4]:31"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Random\n",
    "\n",
    "# Create a small neural network with random weights\n",
    "begin\n",
    "    Random.seed!(1234);\n",
    "\n",
    "    model = Chain(\n",
    "        Dense(2 => 10, relu),\n",
    "        Dense(10 => 50, relu),\n",
    "        Dense(50 => 20, relu),\n",
    "        Dense(20 => 5, relu),\n",
    "        Dense(5 => 1)\n",
    "    )\n",
    "end\n",
    "\n",
    "# Create the workers\n",
    "using Distributed\n",
    "addprocs(4)\n",
    "@everywhere using Gurobi\n",
    "\n",
    "# In order to prevent Gurobi obtaining a new license for each solve\n",
    "@everywhere ENV = Ref{Gurobi.Env}()\n",
    "\n",
    "@everywhere function init_env()\n",
    "    global ENV\n",
    "    ENV[] = Gurobi.Env()\n",
    "end\n",
    "\n",
    "for worker in workers()\n",
    "    fetch(@spawnat worker init_env())\n",
    "end\n",
    "\n",
    "# Regardless of the solver, this must be defined\n",
    "@everywhere using JuMP\n",
    "\n",
    "@everywhere function set_solver!(jump)\n",
    "    set_optimizer(jump, () -> Gurobi.Optimizer(ENV[]))\n",
    "    set_silent(jump)\n",
    "end\n",
    "\n",
    "# Set upper and lower input bounds\n",
    "init_U = [1.0, 1.0];\n",
    "init_L = [-1.0, -1.0];\n",
    "\n",
    "@everywhere using Gogeta\n",
    "\n",
    "# Create a JuMP model from the neural network with parallel bound tightening.\n",
    "jump = Model()\n",
    "@time U, L = NN_formulate!(jump, model, init_U, init_L; bound_tightening=\"standard\", silent=false, parallel=true);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
