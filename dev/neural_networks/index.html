<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Neural networks · Gogeta.jl</title><meta name="title" content="Neural networks · Gogeta.jl"/><meta property="og:title" content="Neural networks · Gogeta.jl"/><meta property="twitter:title" content="Neural networks · Gogeta.jl"/><meta name="description" content="Documentation for Gogeta.jl."/><meta property="og:description" content="Documentation for Gogeta.jl."/><meta property="twitter:description" content="Documentation for Gogeta.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">Gogeta.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Introduction</a></li><li><a class="tocitem" href="../tree_ensembles/">Tree ensembles</a></li><li class="is-active"><a class="tocitem" href>Neural networks</a><ul class="internal"><li><a class="tocitem" href="#Formulation"><span>Formulation</span></a></li><li><a class="tocitem" href="#Convolutional-neural-networks"><span>Convolutional neural networks</span></a></li><li><a class="tocitem" href="#Bound-tightening"><span>Bound tightening</span></a></li><li><a class="tocitem" href="#Sampling"><span>Sampling</span></a></li><li><a class="tocitem" href="#Recommendations"><span>Recommendations</span></a></li></ul></li><li><a class="tocitem" href="../api/">Public API</a></li><li><a class="tocitem" href="../literature/">Literature</a></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Neural networks</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Neural networks</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/gamma-opt/Gogeta.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/gamma-opt/Gogeta.jl/blob/main/docs/src/neural_networks.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Neural-networks"><a class="docs-heading-anchor" href="#Neural-networks">Neural networks</a><a id="Neural-networks-1"></a><a class="docs-heading-anchor-permalink" href="#Neural-networks" title="Permalink"></a></h1><p>With neural networks, the hidden layers must use the <span>$ReLU$</span> activation function, and the output layer must use the identity activation.</p><p>A neural networks satifying these requirements can be formulated into a mixed-integer optimization problem.  Along with formulation, the neuron activation bounds can be calculated, which improves computational performance as well as enables compression.</p><p>The network is compressed by pruning neurons that are either stabily active or inactive. The activation bounds are used to identify these neurons.</p><h2 id="Formulation"><a class="docs-heading-anchor" href="#Formulation">Formulation</a><a id="Formulation-1"></a><a class="docs-heading-anchor-permalink" href="#Formulation" title="Permalink"></a></h2><p>First, create a neural network model satisfying the requirements:</p><pre><code class="language-julia hljs">using Flux

model = Chain(
    Dense(2 =&gt; 10, relu),
    Dense(10 =&gt; 20, relu),
    Dense(20 =&gt; 5, relu),
    Dense(5 =&gt; 1)
)</code></pre><p>Then define the bounds for the input variables. These will be used to calculate the activation bounds for the subsequent layers.</p><pre><code class="language-julia hljs">init_U = [-0.5, 0.5];
init_L = [-1.5, -0.5];</code></pre><p>Now the neural network can be formulated into a MIP. Here optimization-based bound tightening is also used.</p><pre><code class="language-julia hljs">jump_model = Model(Gurobi.Optimizer)
set_silent(model) # set desired parameters

bounds_U, bounds_L = NN_formulate!(jump_model, model, init_U, init_L; bound_tightening=&quot;standard&quot;)</code></pre><p>Using these bounds, the model can be compressed.</p><pre><code class="language-julia hljs">compressed, removed = NN_compress(model, init_U, init_L, bounds_U, bounds_L)</code></pre><p>Compression can also be done without precomputed bounds.</p><pre><code class="language-julia hljs">bounds_U, bounds_L = NN_formulate!(jump_model, model, init_U, init_L; bound_tightening=&quot;standard&quot;, compress=true)</code></pre><p>Use the <code>JuMP</code> model to calculate a forward pass through the network (input at the center of the domain).</p><pre><code class="language-julia hljs">forward_pass!(jump_model, [-1.0, 0.0])</code></pre><p>Finding the optimum of the neural network is now very straightforward.</p><pre><code class="language-julia hljs">last_layer, _ = maximum(keys(jump_model[:x].data))
@objective(jump_model, Max, jump_model[:x][last_layer, 1]) # maximize the output neuron
optimize!(jump_model)
value.(jump_model[:x][0, :]) # maximum
objective_value(jump_model) # neural network output at maximum</code></pre><h2 id="Convolutional-neural-networks"><a class="docs-heading-anchor" href="#Convolutional-neural-networks">Convolutional neural networks</a><a id="Convolutional-neural-networks-1"></a><a class="docs-heading-anchor-permalink" href="#Convolutional-neural-networks" title="Permalink"></a></h2><p>The convolutional neural network requirements can be found in the <a href="../reference/#Gogeta.CNN_formulate!-Tuple{JuMP.Model, Flux.Chain, CNNStructure}"><code>CNN_formulate!</code></a> documentation.</p><p>First, create some kind of input (or load an image from your computer).</p><pre><code class="language-julia hljs">input = rand(Float32, 70, 50, 1, 1) # BW 70x50 image</code></pre><p>Then, create a convolutional neural network model satisfying the requirements:</p><pre><code class="language-julia hljs">using Flux

CNN_model = Flux.Chain(
    Conv((4,3), 1 =&gt; 10, pad=(2, 1), stride=(3, 2), relu),
    MeanPool((5,3), pad=(3, 2), stride=(2, 2)),
    MaxPool((3,4), pad=(1, 3), stride=(3, 2)),
    Conv((4,3), 10 =&gt; 5, pad=(2, 1), stride=(3, 2), relu),
    MaxPool((3,4), pad=(1, 3), stride=(3, 2)),
    Flux.flatten,
    Dense(20 =&gt; 100, relu),
    Dense(100 =&gt; 1)
)</code></pre><p>Then, create an empty <code>JuMP</code> model, extract the layer structure of the CNN model and finally formulate the MIP.</p><pre><code class="language-julia hljs">jump = Model(Gurobi.Optimizer)
set_silent(jump)
cnns = get_structure(CNN_model, input);
CNN_formulate!(jump, CNN_model, cnns)</code></pre><p>Check that the <code>JuMP</code> model produces the same outputs as the <code>Flux.Chain</code>.</p><pre><code class="language-julia hljs">vec(CNN_model(input)) ≈ image_pass!(jump, input)</code></pre><h2 id="Bound-tightening"><a class="docs-heading-anchor" href="#Bound-tightening">Bound tightening</a><a id="Bound-tightening-1"></a><a class="docs-heading-anchor-permalink" href="#Bound-tightening" title="Permalink"></a></h2><p>To improve the computational feasibility of the mixed-integer formulation of a neural network, the big-M values associated with the some of the constraints can be made smaller by calculating the minimum and and maximum activations of the individual neurons. This can be done with a heuristic algorithm or by using mathematical optimization.</p><p>Our package includes three different modes of bound tightening: <code>fast</code> <em>(default)</em>, <code>standard</code> and <code>output</code>.</p><ol><li>The <code>fast</code> mode uses a heuristic algorithm to determine the neuron activation bounds only based on the activation bounds of the previous layer. This algorithm practically doesn&#39;t increase the formulation time, so it is enabled by default. </li><li>The <code>standard</code> mode considers the whole mixed-integer problem with variables and constraints defined up to the previous layer from the neuron under bound tightening. It uses optimization to find the neuron activation bounds and is therefore significantly slower than the <code>fast</code> mode but is able to produce tighter bounds (smaller big-M values).</li><li>In some situations, the user might know the bounds for the output layer neurons. The <code>output</code> mode takes into account these output bounds as well as the whole MIP. Therefore, it is able to produce the tightest bounds of all the methods listed, but it is also the slowest.</li></ol><p>(<code>precomputed</code> is also one of the bound tightening options in the functions. It can be used by inputting bounds that have already been calculated.)</p><p>A detailed discussion on bound tightening techniques can be found in <a href="../literature/">Grimstad and Andresson (2019)</a>.</p><h2 id="Sampling"><a class="docs-heading-anchor" href="#Sampling">Sampling</a><a id="Sampling-1"></a><a class="docs-heading-anchor-permalink" href="#Sampling" title="Permalink"></a></h2><p>Instead of just solving the MIP, the neural network can be optimized (finding the output maximizing/minimizing input) by using a sampling approach. Note that these features are experimental and cannot be guranteed to find the global optimum.</p><pre><code class="language-julia hljs">using QuasiMonteCarlo

jump_model = Model(Gurobi.Optimizer)
set_silent(jump_model)
NN_formulate!(jump_model, NN_model, init_U, init_L; bound_tightening=&quot;fast&quot;);

# set objective function as the last layer output
last_layer, _ = maximum(keys(jump_model[:x].data))
@objective(jump_model, Max, jump_model[:x][last_layer, 1])

samples = QuasiMonteCarlo.sample(1000, init_L, init_U, LatinHypercubeSample());
x_opt, optimum = optimize_by_sampling!(jump_model, samples);</code></pre><h3 id="Relaxing-walk-algorithm"><a class="docs-heading-anchor" href="#Relaxing-walk-algorithm">Relaxing walk algorithm</a><a id="Relaxing-walk-algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Relaxing-walk-algorithm" title="Permalink"></a></h3><p>Another method for heuristically optimizing the JuMP model is the so-called relaxing walk algorithm. It is based on a sampling approach that utilizes LP relaxations of the original problem and a pseudo gradient descent -algorithm.</p><pre><code class="language-julia hljs">jump_model = Model(Gurobi.Optimizer)
set_silent(jump_model)
NN_formulate!(jump_model, NN_model, init_U, init_L; bound_tightening=&quot;fast&quot;)

# set objective function as the last layer output
last_layer, _ = maximum(keys(jump_model[:x].data))
@objective(jump_model, Max, jump_model[:x][last_layer, 1])

x_opt, optimum = optimize_by_walking!(jump_model, init_U, init_L)</code></pre><p>A <code>set_solver!</code> -function must be specified (used for copying the model in the algorithm).</p><pre><code class="language-julia hljs">function set_solver!(jump)
    set_optimizer(jump, Gurobi.Optimizer)
    set_silent(jump)
end</code></pre><h2 id="Recommendations"><a class="docs-heading-anchor" href="#Recommendations">Recommendations</a><a id="Recommendations-1"></a><a class="docs-heading-anchor-permalink" href="#Recommendations" title="Permalink"></a></h2><p>The choice of the best neural network bound tightening and compression procedures depends heavily on your specific use case.  Based on some limited computational tests of our own as well as knowledge from the field, we can make the following general recommendations:</p><ul><li>Wide but shallow neural networks should be preferred. The bound tightening gets exponentially harder with deeper layers.</li><li>For small neural network models, using the &quot;fast&quot; bound tightening option is probably the best, since the resulting formulations are easy to solve even with loose bounds.</li><li>For larger neural networks, &quot;standard&quot; bound tightening will produce tighter bounds but take more time. However, when using the <code>JuMP</code> model, the tighter bounds might make it more computationally feasible.</li><li>For large neural networks where the output bounds are known, &quot;output&quot; bound tightening can be used. This bound tightening is very slow but might be necessary to increase the computational feasibility of the resulting <code>JuMP</code> model.</li><li>If the model has many so-called &quot;dead&quot; neurons, creating the JuMP model by using compression is beneficial, since the formulation will have fewer constraints and the bound tightening will be faster, reducing total formulation time.</li></ul><p>These are only general recommendations based on limited evidence, and the user should validate the performance of each bound tightening and compression procedure in relation to her own work.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tree_ensembles/">« Tree ensembles</a><a class="docs-footer-nextpage" href="../api/">Public API »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Tuesday 18 June 2024 15:09">Tuesday 18 June 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
