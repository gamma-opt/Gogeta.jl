{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: Chain, Dense, relu, mse, train!, params, ADAM\n",
    "using Random\n",
    "using Gogeta\n",
    "using Plots\n",
    "using Gurobi\n",
    "using JuMP\n",
    "using LaTeXStrings\n",
    "using CSV\n",
    "using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Psplits (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Psplits(X::AbstractVector, P::Integer)\n",
    "    #l%P sub-arrays of size (1//P)+1 and the rest 1//P\n",
    "    #returns the sorted indices\n",
    "    parts = Vector{Vector{Int64}}(undef, P)\n",
    "\n",
    "    l = length(X)\n",
    "    n = l % P\n",
    "\n",
    "    s2 = (l÷P)\n",
    "\n",
    "    if n > 0\n",
    "        s1 = (l÷P)+1\n",
    "        for k in 1:n\n",
    "            parts[k] = X[1+(k-1)*s1:(k-1)*s1+s1]\n",
    "        end\n",
    "    else\n",
    "        s1 = 0\n",
    "    end\n",
    "    \n",
    "    for k in n+1:P\n",
    "        parts[k] = X[1+n*s1+(k-1-n)*s2:n*s1+(k-1-n)*s2+s2]\n",
    "    end\n",
    "    \n",
    "    return parts\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN_formulate_Psplit! (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function NN_formulate_Psplit!(jump_model::JuMP.Model, NN_model::Flux.Chain, P, init_U, init_L; silent=true)\n",
    "\n",
    "    oldstdout = stdout\n",
    "    if silent redirect_stdout(devnull) end\n",
    "    println(\"Creating JuMP model...\")\n",
    "    empty!(jump_model)\n",
    "\n",
    "    K = length(NN_model); # number of layers (input layer not included)\n",
    "    W = deepcopy([Flux.params(NN_model)[2*k-1] for k in 1:K]);\n",
    "    b = deepcopy([Flux.params(NN_model)[2*k] for k in 1:K]);\n",
    "\n",
    "\n",
    "    @assert all([NN_model[i].σ == relu for i in 1:K-1]) \"Neural network must use the relu activation function.\"\n",
    "    @assert NN_model[K].σ == identity \"Neural network must use the identity function for the output layer.\"\n",
    "    @assert P > 0 \"The number of splits must be more than 0.\"\n",
    "\n",
    "    input_length = Int((length(W[1]) / length(b[1])))\n",
    "    neuron_count = [length(b[k]) for k in eachindex(b)]\n",
    "    neurons(layer) = layer == 0 ? [i for i in 1:input_length] : [i for i in 1:neuron_count[layer]]\n",
    "\n",
    "    @variable(jump_model, x[layer = 0:K, neurons(layer)]);\n",
    "    @variable(jump_model, sigma[layer = 1:K-1, neurons(layer)]);\n",
    "    @variable(jump_model, z_b[layer = 1:K-1, neurons(layer), p=1:P]);\n",
    "\n",
    "    @constraint(jump_model, [j = 1:input_length], x[0, j] <= init_U[j])\n",
    "    @constraint(jump_model, [j = 1:input_length], x[0, j] >= init_L[j])\n",
    "\n",
    "    bounds_U = Vector{Vector}(undef, K)\n",
    "    bounds_L = Vector{Vector}(undef, K)\n",
    "\n",
    "    UB_α = Vector{Vector{Vector}}(undef, K-1)\n",
    "    LB_α = Vector{Vector{Vector}}(undef, K-1)\n",
    "\n",
    "    [UB_α[layer] = Vector{Vector}(undef, neuron_count[layer]) for layer in 1:K-1]\n",
    "    [LB_α[layer] = Vector{Vector}(undef, neuron_count[layer]) for layer in 1:K-1]\n",
    "\n",
    "    for layer in 1:K # hidden layers and output layer\n",
    "\n",
    "        println(\"\\nLAYER $layer\")\n",
    "\n",
    "        if layer == 1\n",
    "\n",
    "            bounds_U[layer] = [sum(max(W[layer][neuron, previous] * init_U[previous], W[layer][neuron, previous] * init_L[previous]) for previous in neurons(layer-1)) + b[layer][neuron] for neuron in neurons(layer)]\n",
    "            bounds_L[layer] = [sum(min(W[layer][neuron, previous] * init_U[previous], W[layer][neuron, previous] * init_L[previous]) for previous in neurons(layer-1)) + b[layer][neuron] for neuron in neurons(layer)]\n",
    "        else\n",
    "            \n",
    "            bounds_U[layer] = [sum(bounds_U[layer-1][previous]*max(0, W[layer][neuron, previous]) + bounds_L[layer-1][previous]*min(0, W[layer][neuron, previous]) for previous in neurons(layer-1)) + b[layer][neuron] for neuron in neurons(layer)]\n",
    "            bounds_L[layer] = [sum(bounds_L[layer-1][previous]*max(0, W[layer][neuron, previous]) + bounds_U[layer-1][previous]*min(0, W[layer][neuron, previous]) for previous in neurons(layer-1)) + b[layer][neuron] for neuron in neurons(layer)]\n",
    "        end\n",
    "        # output bounds calculated but no more constraints added\n",
    "        if layer == K\n",
    "            break\n",
    "        end\n",
    "\n",
    "        [UB_α[layer][neuron] = Vector(undef, P) for neuron in 1:neuron_count[layer]]\n",
    "        [LB_α[layer][neuron] = Vector(undef, P) for neuron in 1:neuron_count[layer]]\n",
    "\n",
    "        @constraint(jump_model, [neuron in neurons(layer)], x[layer, neuron] <= max(0, bounds_U[layer][neuron]))\n",
    "        @constraint(jump_model, [neuron in neurons(layer)], x[layer, neuron] >= 0)\n",
    "\n",
    "        for neuron in neurons(layer)\n",
    "\n",
    "            split_indices = Psplits(sortperm(W[layer][neuron, :]), P)\n",
    "            set_binary(sigma[layer, neuron])\n",
    "            \n",
    "            @constraint(jump_model, sum(sum(W[layer][neuron, i]*x[layer-1, i] for i in split_indices[p])-z_b[layer, neuron, p] for p in 1:P) + sigma[layer, neuron]*b[layer][neuron]<=0)\n",
    "            @constraint(jump_model, sum(z_b[layer, neuron, p] for p in 1:P) + (1-sigma[layer,neuron])*b[layer][neuron]>=0)\n",
    "            @constraint(jump_model, x[layer, neuron] == sum(z_b[layer, neuron, p] for p in 1:P) + (1-sigma[layer,neuron])*b[layer][neuron]) \n",
    "\n",
    "            for p in 1:P\n",
    "            \n",
    "                if layer == 1\n",
    "                    UB_α[layer][neuron][p] = sum(max(W[layer][neuron, previous] * init_U[previous], W[layer][neuron, previous] * init_L[previous]) for previous in split_indices[p])\n",
    "                    LB_α[layer][neuron][p] = sum(min(W[layer][neuron, previous] * init_U[previous], W[layer][neuron, previous] * init_L[previous]) for previous in split_indices[p])\n",
    "                else\n",
    "                    UB_α[layer][neuron][p] = sum(max(W[layer][neuron, previous] * max(0, bounds_U[layer-1][previous]), W[layer][neuron, previous] * max(0, bounds_L[layer-1][previous])) for previous in split_indices[p])\n",
    "                    LB_α[layer][neuron][p] = sum(min(W[layer][neuron, previous] * max(0, bounds_U[layer-1][previous]), W[layer][neuron, previous] * max(0, bounds_L[layer-1][previous])) for previous in split_indices[p])\n",
    "                end\n",
    "                \n",
    "\n",
    "                @constraint(jump_model, sigma[layer, neuron]*LB_α[layer][neuron][p]<=sum(W[layer][neuron, i]*x[layer-1, i] for i in split_indices[p])-z_b[layer, neuron, p])\n",
    "                @constraint(jump_model, sum(W[layer][neuron, i]*x[layer-1, i] for i in split_indices[p])-z_b[layer, neuron, p]<=sigma[layer, neuron]*UB_α[layer][neuron][p]) \n",
    "                @constraint(jump_model, (1-sigma[layer, neuron])*LB_α[layer][neuron][p]<=z_b[layer, neuron, p])\n",
    "                @constraint(jump_model, z_b[layer, neuron, p]<=(1-sigma[layer, neuron])*UB_α[layer][neuron][p])\n",
    "\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # output layer\n",
    "    @constraint(jump_model, [neuron in neurons(K)], x[K, neuron] <= max(0, bounds_U[K][neuron]))\n",
    "    @constraint(jump_model, [neuron in neurons(K)], x[K, neuron] >= min(0, bounds_L[K][neuron]))\n",
    "    @constraint(jump_model, [neuron in neurons(K)], x[K, neuron] == b[K][neuron] + sum(W[K][neuron, i] * x[K-1, i] for i in neurons(K-1)))\n",
    "\n",
    "    #A dummy objective\n",
    "    @objective(jump_model, Max, 1);\n",
    "    redirect_stdout(oldstdout)\n",
    "\n",
    "    return bounds_U, bounds_L\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin\n",
    "    Random.seed!(1234);\n",
    "\n",
    "    NN_model = Chain(\n",
    "        Dense(4 => 8, relu),\n",
    "        Dense(8 => 16, relu),\n",
    "        Dense(16 => 1)\n",
    "        \n",
    "    )\n",
    "end\n",
    "\n",
    "init_U = [1, 1, 1, 1];\n",
    "init_L = [0, 0, 0, 0];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-05-20\n",
      "  0.228972 seconds (418.50 k allocations: 28.285 MiB, 4.84% gc time, 99.12% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "A JuMP Model\n",
       "Maximization problem with:\n",
       "Variables: 101\n",
       "Objective function type: AffExpr\n",
       "`AffExpr`-in-`MathOptInterface.EqualTo{Float64}`: 25 constraints\n",
       "`AffExpr`-in-`MathOptInterface.GreaterThan{Float64}`: 53 constraints\n",
       "`AffExpr`-in-`MathOptInterface.LessThan{Float64}`: 245 constraints\n",
       "`VariableRef`-in-`MathOptInterface.ZeroOne`: 24 constraints\n",
       "Model mode: AUTOMATIC\n",
       "CachingOptimizer state: EMPTY_OPTIMIZER\n",
       "Solver name: Gurobi\n",
       "Names registered in the model: sigma, x, z_b"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jump_model = Model(Gurobi.Optimizer);\n",
    "set_silent(jump_model) #disables output of the optimazer\n",
    "set_attribute(jump_model, \"TimeLimit\", 10) #sets the time limit to be 10 seconds\n",
    "\n",
    "P = 2\n",
    "@time bounds_U, bounds_L = NN_formulate_Psplit!(jump_model, NN_model, P, init_U, init_L)\n",
    "jump_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.537365 seconds (1.69 M allocations: 112.613 MiB, 6.10% gc time, 97.39% compilation time: 4% of which was recompilation)\n",
      "The model found next solution:\n",
      "  [1]  =  1.0\n",
      "  [2]  =  1.0\n",
      "  [3]  =  0.0\n",
      "  [4]  =  0.0\n",
      "With objective function: 0.40986967350298237\n",
      "The output of the NN for solution given by jump model: 0.40986964\n"
     ]
    }
   ],
   "source": [
    "output_neuron = jump_model[:x][maximum(keys(jump_model[:x].data))]\n",
    "@objective(jump_model, Max, output_neuron);\n",
    "\n",
    "@time optimize!(jump_model)\n",
    "println(\"The model found next solution:\\n\", value.(jump_model[:x][0, :]))\n",
    "println(\"With objective function: \", objective_value(jump_model) )\n",
    "solution = Float32.([i for i in value.(jump_model[:x][0, :])])\n",
    "println(\"The output of the NN for solution given by jump model: \", NN_model(solution)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.10855757781568458], Float32[0.10855755])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass!(jump_model, [1, 1, 1, 1]), NN_model([1,1,1,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
