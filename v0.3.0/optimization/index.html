<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Optimization · Gogeta.jl</title><meta name="title" content="Optimization · Gogeta.jl"/><meta property="og:title" content="Optimization · Gogeta.jl"/><meta property="twitter:title" content="Optimization · Gogeta.jl"/><meta name="description" content="Documentation for Gogeta.jl."/><meta property="og:description" content="Documentation for Gogeta.jl."/><meta property="twitter:description" content="Documentation for Gogeta.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">Gogeta.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Introduction</a></li><li><span class="tocitem">Features</span><ul><li><input class="collapse-toggle" id="menuitem-2-1" type="checkbox" checked/><label class="tocitem" for="menuitem-2-1"><span class="docs-label">Neural networks</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../nns_introduction/">General</a></li><li><a class="tocitem" href="../neural_networks/">Big-M formulation</a></li><li><a class="tocitem" href="../psplit_nns/">Partition-based formulation</a></li><li class="is-active"><a class="tocitem" href>Optimization</a><ul class="internal"><li><a class="tocitem" href="#Direct-optimization"><span>Direct optimization</span></a></li><li><a class="tocitem" href="#Sampling"><span>Sampling</span></a></li><li><a class="tocitem" href="#Relaxing-walk-algorithm"><span>Relaxing walk algorithm</span></a></li></ul></li><li><a class="tocitem" href="../nns_in_larger/">Use as surrogates</a></li></ul></li><li><a class="tocitem" href="../icnns/">Input convex neural networks</a></li><li><a class="tocitem" href="../cnns/">Convolutional neural networks</a></li><li><a class="tocitem" href="../tree_ensembles/">Tree ensembles</a></li></ul></li><li><a class="tocitem" href="../literature/">Literature</a></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Features</a></li><li><a class="is-disabled">Neural networks</a></li><li class="is-active"><a href>Optimization</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Optimization</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/gamma-opt/Gogeta.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/gamma-opt/Gogeta.jl/blob/main/docs/src/optimization.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Finding-the-optimum-of-the-neural-network"><a class="docs-heading-anchor" href="#Finding-the-optimum-of-the-neural-network">Finding the optimum of the neural network</a><a id="Finding-the-optimum-of-the-neural-network-1"></a><a class="docs-heading-anchor-permalink" href="#Finding-the-optimum-of-the-neural-network" title="Permalink"></a></h1><p>Being able to formulate NNs as a MIPs gives us the possibility to optimize over &quot;black box&quot; models. For instance, imagine that we have a dataset with some information about houses and their associated prices. With a NN trained on this dataset and its MIP formulation, we can find what kind of houses would be the most affordable and the most expensive. We could also add some additional constraints to the &quot;target&quot; house and see what is the possible range of prices.</p><p>In this section, we will optimize over the output neuron of NNs, but you can choose any objective function. The variable associated with the output neuron can be extracted in the following way:</p><pre><code class="language-julia hljs">output_neuron = jump_model[:x][maximum(keys(jump_model[:x].data))]
@objective(jump_model, Max, output_neuron) # maximize the output neuron</code></pre><h2 id="Direct-optimization"><a class="docs-heading-anchor" href="#Direct-optimization">Direct optimization</a><a id="Direct-optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Direct-optimization" title="Permalink"></a></h2><p>We can optimize the model directly.</p><pre><code class="language-julia hljs">optimize!(jump_model)
value.(jump_model[:x][0, :]) # maximum
objective_value(jump_model) # neural network output at maximum</code></pre><h2 id="Sampling"><a class="docs-heading-anchor" href="#Sampling">Sampling</a><a id="Sampling-1"></a><a class="docs-heading-anchor-permalink" href="#Sampling" title="Permalink"></a></h2><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>This method works only with the Big-M formulation</p></div></div><p>Instead of just solving the MILP, the neural network can be optimized (finding the output maximizing/minimizing input) by using a sampling approach. See <a href="https://github.com/gamma-opt/Gogeta.jl/blob/main/examples/neural_networks/example_4_nn_relaxing_walk.ipynb">jupyter notebook</a> for a more detailed example.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Much more effective algorithms for finding the optimum of a trained neural network exist, such as projected gradient descent. The sampling-based optimization algorithms implemented in this package are best intended for satisfying one&#39;s curiosity and understanding the problem structure better.</p></div></div><p>First we formulate the NN as a MIP</p><pre><code class="language-julia hljs">using QuasiMonteCarlo

jump_model = Model(Gurobi.Optimizer)
set_silent(jump_model)
NN_formulate!(jump_model, NN_model, init_U, init_L; bound_tightening=&quot;fast&quot;);</code></pre><p>Then, we set objective function to either minimize or maximize the output neuron.</p><pre><code class="language-julia hljs"># set objective function as the last layer output
output_neuron = jump_model[:x][maximum(keys(jump_model[:x].data))]
@objective(jump_model, Max, output_neuron)</code></pre><p>Randomly generate samples that aling with lower and upper bounds. Call function <code>optimize_by_sampling!</code> that returns nearly optimum solution.</p><pre><code class="language-julia hljs">samples = QuasiMonteCarlo.sample(1000, init_L, init_U, LatinHypercubeSample());
x_opt, optimum = optimize_by_sampling!(jump_model, samples);</code></pre><h2 id="Relaxing-walk-algorithm"><a class="docs-heading-anchor" href="#Relaxing-walk-algorithm">Relaxing walk algorithm</a><a id="Relaxing-walk-algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Relaxing-walk-algorithm" title="Permalink"></a></h2><p>Another method for heuristically optimizing the JuMP model is the so-called relaxing walk algorithm. It is based on a sampling approach that utilizes LP relaxations of the original problem and a pseudo gradient descent -algorithm. It uses function <a href="../reference/#Gogeta.optimize_by_walking!-Tuple{JuMP.Model, Flux.Chain, Any, Any}"><code>optimize_by_walking!</code></a>. See <a href="https://github.com/gamma-opt/Gogeta.jl/blob/main/examples/neural_networks/example_3_nn_sampling.ipynb">jupyter notebook</a> for a more detailed example.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>This method works only with Big-M formulation of NN</p></div></div><pre><code class="language-julia hljs">jump_model = Model(Gurobi.Optimizer)
set_silent(jump_model)
NN_formulate!(jump_model, NN_model, init_U, init_L; bound_tightening=&quot;fast&quot;)
# set objective function as the last layer output
output_neuron = jump_model[:x][maximum(keys(jump_model[:x].data))]
@objective(jump_model, Max, output_neuron)
x_opt, optimum = optimize_by_walking!(jump_model, NN_model, init_U, init_L)</code></pre><p>A <code>set_solver!</code> - function must be specified (used for copying the model in the algorithm). This function is different depending on the optimizer.</p><pre><code class="language-julia hljs">function set_solver!(jump)
    set_optimizer(jump, Gurobi.Optimizer)
    set_silent(jump)
end</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../psplit_nns/">« Partition-based formulation</a><a class="docs-footer-nextpage" href="../nns_in_larger/">Use as surrogates »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.6.0 on <span class="colophon-date" title="Wednesday 21 August 2024 12:14">Wednesday 21 August 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
